{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Pandas to PostgreSQL: Bulk Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By Naysan Saran, May 2020.*  \n",
    "Updated in June 2020 by Naysan Saran <br/>\n",
    "Updated in July 2022 by Mahery Ranaivoson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will go through all the steps required to \n",
    "\n",
    "- turn a csv into a pandas dataframe\n",
    "- create the corresponding PostgreSQL database and table\n",
    "- insert the pandas dataframe in the PostgreSQL table using different insert techniques\n",
    "- benchmark them to see which one is faster\n",
    "\n",
    "The data for this tutorial is freely available on https://datahub.io/core/global-temp, but you will also find it in the data/ directory of this github repository. What is nice about this dataframe is that it contains string, date and float columns, so it should be a good test dataframe for the benchmarking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - From csv file to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows = 3288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCAG</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>0.7895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GISTEMP</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>0.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCAG</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>0.7504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source        Date    Mean\n",
       "0     GCAG  2016-12-06  0.7895\n",
       "1  GISTEMP  2016-12-06  0.8100\n",
       "2     GCAG  2016-11-06  0.7504"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = \"data/global-temp-monthly.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "print(\"Total number of rows = %s\" % len(df.index))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>datetime</th>\n",
       "      <th>mean_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCAG</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>0.7895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GISTEMP</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>0.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCAG</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>0.7504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source    datetime  mean_temp\n",
       "0     GCAG  2016-12-06     0.7895\n",
       "1  GISTEMP  2016-12-06     0.8100\n",
       "2     GCAG  2016-11-06     0.7504"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\n",
    "    \"Source\": \"source\", \n",
    "    \"Date\": \"datetime\",\n",
    "    \"Mean\": \"mean_temp\"\n",
    "})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - PostgreSQL database, table and user setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the database. I'm assuming you already have PostgreSQL installed on your system. Otherwise you can refer to this link first https://www.postgresql.org/download/.\n",
    "\n",
    "Creating the database - Ubuntu command line instructions   \n",
    "\n",
    "<code>>> sudo -i -u postgres</code>  \n",
    "<code>>> psql</code>  \n",
    "<code>postgres=# CREATE DATABASE globaldata;</code>  \n",
    "<code>postgres=# \\c globaldata;</code>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we are going to create one table only to store everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "postgres=# CREATE TABLE monthlytemp ( <br>\n",
    "   id SERIAL PRIMARY KEY, <br>\n",
    "   source VARCHAR (16) NOT NULL, <br>\n",
    "   datetime DATE, <br>\n",
    "   mean_temp FLOAT <br>\n",
    ");\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's create a user and give them access to our new table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code> \n",
    "postgres=# CREATE USER myuser WITH PASSWORD 'Passw0rd'; <br>\n",
    "postgres=# GRANT SELECT, INSERT, DELETE, UPDATE on MonthlyTemp to myuser;\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last permission to grant, so 'myuser' can autoincrement the 'id' primary key without having to specify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "postgres=# GRANT USAGE on sequence monthlytemp_id_seq to myuser; <br>\n",
    "postgres=# \\q \n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Basic Python functions to access the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright back to Python. Here are all the functions we will need. For a complete, functioning code, please refer to the src/ subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import sys \n",
    "# Since we want to benchmark the efficiency of each insert strategy\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, let's specify the connection parameters as a Python dictionary. The database, username and password will be the same that we created in part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic = {\n",
    "    \"host\"      : \"172.18.0.3\",\n",
    "    \"database\"  : \"globaldata\",\n",
    "    \"user\"      : \"myuser\",\n",
    "    \"password\"  : \"Passw0rd\",\n",
    "    \"port\"      : 5432\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will allow us to connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "        conn.autocommit = True\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "conn = connect(param_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to execute any query in the database. Will come in handy later as we test multiple insert tactics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(conn, query):\n",
    "    \"\"\" Execute a single query \"\"\"\n",
    "    \n",
    "    ret = 0 # Return value\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "\n",
    "    # If this was a select query, return the result\n",
    "    if 'select' in query.lower():\n",
    "        ret = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Bulk Insert Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - ExecuteMany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_many() done\n"
     ]
    }
   ],
   "source": [
    "def execute_many(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using cursor.executemany() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES(%%s,%%s,%%s)\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.executemany(query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_many() done\")\n",
    "    cursor.close()\n",
    "\n",
    "# Run the execute_many strategy\n",
    "execute_many(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - ExecuteBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_batch() done\n"
     ]
    }
   ],
   "source": [
    "import psycopg2.extras as extras\n",
    "\n",
    "def execute_batch(conn, df, table, page_size=100):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_batch() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES(%%s,%%s,%%s)\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_batch(cursor, query, tuples, page_size)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_batch() done\")\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "# Run the execute_many strategy\n",
    "execute_batch(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - ExecuteValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_values() done\n"
     ]
    }
   ],
   "source": [
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "# Run the execute_many strategy\n",
    "execute_values(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D - Mogrify() then execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_mogrify() done\n"
     ]
    }
   ],
   "source": [
    "def execute_mogrify(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using cursor.mogrify() to build the bulk insert query\n",
    "    then cursor.execute() to execute the query\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    cursor = conn.cursor()\n",
    "    values = [cursor.mogrify(\"(%s,%s,%s)\", tup).decode('utf8') for tup in tuples]\n",
    "    query  = \"INSERT INTO %s(%s) VALUES \" % (table, cols) + \",\".join(values)\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_mogrify() done\")\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "# Run the execute_many strategy\n",
    "execute_mogrify(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E - CopyFrom() - Save to disk first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_file() done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def copy_from_file(conn, df, table):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe on disk as \n",
    "    a csv file, load the csv file  \n",
    "    and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # Save the dataframe to disk\n",
    "    tmp_df = \"./tmp_dataframe.csv\"\n",
    "    df.to_csv(tmp_df, index_label='id', header=False)\n",
    "    f = open(tmp_df, 'r')\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(f, table, sep=\",\")\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        os.remove(tmp_df)\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"copy_from_file() done\")\n",
    "    cursor.close()\n",
    "    os.remove(tmp_df)\n",
    "\n",
    "\n",
    "# Run the execute_many strategy\n",
    "copy_from_file(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F - CopyFrom() - In memory using StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_stringio() done\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "def copy_from_stringio(conn, df, table):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe in memory \n",
    "    and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # save dataframe to an in memory buffer\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index_label='id', header=False)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(buffer, table, sep=\",\")\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"copy_from_stringio() done\")\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "# Run the execute_many strategy\n",
    "copy_from_stringio(conn, df, 'monthlytemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the values were indeed inserted\n",
    "execute_query(conn, \"select count(*) from monthlytemp;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from monthlytemp where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G - to_sql() - From sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are using a different library to connect to the database (SqlAlchemy), we have to connect again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_sql() done (sqlalchemy)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = \"postgresql+psycopg2://%s:%s@%s:5432/%s\" % (\n",
    "    param_dic['user'],\n",
    "    param_dic['password'],\n",
    "    param_dic['host'],\n",
    "    param_dic['database']\n",
    ")\n",
    "\n",
    "def to_alchemy(df):\n",
    "    \"\"\"\n",
    "    Using a dummy table to test this call library\n",
    "    \"\"\"\n",
    "    engine = create_engine(connect)\n",
    "    df.to_sql(\n",
    "        name='to_sql_table', \n",
    "        con=engine, \n",
    "        index=False, \n",
    "        if_exists='replace'\n",
    "    )\n",
    "    print(\"to_sql() done (sqlalchemy)\")\n",
    "    \n",
    "to_alchemy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(conn, \"select count(*) from to_sql_table;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from to_sql_table where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H - to_sql() having method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_sql_insert_copy() done \n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import csv\n",
    "\n",
    "connect = \"postgresql+psycopg2://%s:%s@%s:5432/%s\" % (\n",
    "    param_dic['user'],\n",
    "    param_dic['password'],\n",
    "    param_dic['host'],\n",
    "    param_dic['database']\n",
    ")\n",
    "\n",
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    \"\"\"\n",
    "    Execute SQL statement inserting data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table : pandas.io.sql.SQLTable\n",
    "    conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection\n",
    "    keys : list of str\n",
    "        Column names\n",
    "    data_iter : Iterable that iterates the values to be inserted\n",
    "    \"\"\"\n",
    "    # gets a DBAPI connection that can provide a cursor\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = ', '.join(['\"{}\"'.format(k) for k in keys])\n",
    "        if table.schema:\n",
    "            table_name = '{}.{}'.format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = 'COPY {} ({}) FROM STDIN WITH CSV'.format(\n",
    "            table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "        \n",
    "def to_sql_insert_copy(df):\n",
    "    \"\"\"\n",
    "    Using a dummy table to test this call library\n",
    "    \"\"\"\n",
    "    engine = create_engine(connect)\n",
    "    \n",
    "    df.to_sql(\n",
    "        name=\"to_sql_insert_copy_table\",\n",
    "        con=engine,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=psql_insert_copy\n",
    "    )\n",
    "    \n",
    "    print(\"to_sql_insert_copy() done \")\n",
    "    \n",
    "to_sql_insert_copy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3288,)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(conn, \"select count(*) from to_sql_insert_copy_table;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the table\n",
    "execute_query(conn, \"delete from to_sql_insert_copy_table where true;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking the performance of each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_inserts() done\n",
      "execute_many() done\n",
      "execute_batch() done\n",
      "execute_values() done\n",
      "execute_mogrify() done\n",
      "copy_from_file() done\n",
      "copy_from_stringio() done\n",
      "to_sql() done (sqlalchemy)\n",
      "to_sql_insert_copy() done \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrows</th>\n",
       "      <th>strategy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3288</td>\n",
       "      <td>single_inserts</td>\n",
       "      <td>2.25296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3288</td>\n",
       "      <td>execute_many</td>\n",
       "      <td>1.94512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3288</td>\n",
       "      <td>execute_batch</td>\n",
       "      <td>0.118874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3288</td>\n",
       "      <td>execute_values</td>\n",
       "      <td>0.0519678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3288</td>\n",
       "      <td>execute_mogrify</td>\n",
       "      <td>0.0366373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3288</td>\n",
       "      <td>copy_from_file</td>\n",
       "      <td>0.0159218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3288</td>\n",
       "      <td>copy_from_stringio</td>\n",
       "      <td>0.0189669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3288</td>\n",
       "      <td>to_sql() | without method</td>\n",
       "      <td>0.271317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3288</td>\n",
       "      <td>to_sql() | with method</td>\n",
       "      <td>0.0386548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nrows                   strategy       time\n",
       "0  3288             single_inserts    2.25296\n",
       "1  3288               execute_many    1.94512\n",
       "2  3288              execute_batch   0.118874\n",
       "3  3288             execute_values  0.0519678\n",
       "4  3288            execute_mogrify  0.0366373\n",
       "5  3288             copy_from_file  0.0159218\n",
       "6  3288         copy_from_stringio  0.0189669\n",
       "7  3288  to_sql() | without method   0.271317\n",
       "8  3288     to_sql() | with method  0.0386548"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_inserts(conn, df, table):\n",
    "    \"\"\"\n",
    "    For benchmarking purposes, let's also implement a strategy in \n",
    "    which the inserts calls are done separately. Here we are \n",
    "    creating and closing a new cursor at each time, so this is probably \n",
    "    one of the slowest ways to achieve what we want.\n",
    "    \"\"\"\n",
    "    for i in df.index:\n",
    "        cols  = ','.join(list(df.columns))\n",
    "        vals  = [df.at[i,col] for col in list(df.columns)]\n",
    "        query = \"INSERT INTO %s(%s) VALUES('%s','%s',%s)\" % (table, cols, vals[0], vals[1], vals[2])\n",
    "        execute_query(conn, query)\n",
    "    print(\"single_inserts() done\")\n",
    "        \n",
    "        \n",
    "#-----------------------------------------\n",
    "# COMPARE THE SPEED OF EACH STRATRGY\n",
    "#-----------------------------------------\n",
    "def benchmark_bulk_inserts(df):\n",
    "    execute_query(conn, \"delete from monthlytemp where true;\")\n",
    "    functions = [\n",
    "        single_inserts, \n",
    "        execute_many, \n",
    "        execute_batch,\n",
    "        execute_values, \n",
    "        execute_mogrify, \n",
    "        copy_from_file,\n",
    "        copy_from_stringio\n",
    "    ]\n",
    "    exec_times = pd.DataFrame(index=range(len(functions)), columns=['nrows','strategy','time'])\n",
    "\n",
    "    # Psycop2's functions\n",
    "    i = 0\n",
    "    for strategy in functions:\n",
    "        start = timer()\n",
    "        strategy(conn, df, 'monthlytemp')\n",
    "        end = timer()\n",
    "        \n",
    "        exec_times.at[i,'nrows'] = len(df.index)\n",
    "        exec_times.at[i,'strategy'] = strategy.__name__\n",
    "        exec_times.at[i,'time'] = end-start\n",
    "        \n",
    "        # Prepare for the next test\n",
    "        execute_query(conn, \"delete from monthlytemp where true;\")\n",
    "        i = i + 1\n",
    "\n",
    "    # Adding an extra test case for sqlalchemy's to_sql\n",
    "    start = timer()\n",
    "    to_alchemy(df)\n",
    "    end = timer()\n",
    "    exec_times.at[i,'nrows'] = len(df.index)\n",
    "    exec_times.at[i,'strategy'] = \"to_sql() | without method\"\n",
    "    exec_times.at[i,'time'] = end-start\n",
    "    \n",
    "    # Adding an extra test case for to_sql_insert_copy\n",
    "    start = timer()\n",
    "    to_sql_insert_copy(df)\n",
    "    end = timer()\n",
    "    exec_times.at[i+1,'nrows'] = len(df.index)\n",
    "    exec_times.at[i+1,'strategy'] = \"to_sql() | with method\"\n",
    "    exec_times.at[i+1,'time'] = end-start\n",
    "    \n",
    "    return exec_times\n",
    "\n",
    "benchmark_bulk_inserts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with 1000 to 100,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101928\n"
     ]
    }
   ],
   "source": [
    "# Repeating our dataframe 30 times to get a large test dataframe\n",
    "big_df = pd.concat([df]*31, ignore_index=True)\n",
    "print(len(big_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'datetime', 'mean_temp'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nrows = 1000\n",
      "single_inserts() done\n",
      "execute_many() done\n",
      "execute_batch() done\n",
      "execute_values() done\n",
      "execute_mogrify() done\n",
      "copy_from_file() done\n",
      "copy_from_stringio() done\n",
      "to_sql() done (sqlalchemy)\n",
      "to_sql_insert_copy() done \n",
      "Nrows = 10000\n",
      "single_inserts() done\n",
      "execute_many() done\n",
      "execute_batch() done\n",
      "execute_values() done\n",
      "execute_mogrify() done\n",
      "copy_from_file() done\n",
      "copy_from_stringio() done\n",
      "to_sql() done (sqlalchemy)\n",
      "to_sql_insert_copy() done \n",
      "Nrows = 50000\n",
      "single_inserts() done\n",
      "execute_many() done\n",
      "execute_batch() done\n",
      "execute_values() done\n",
      "execute_mogrify() done\n",
      "copy_from_file() done\n",
      "copy_from_stringio() done\n",
      "to_sql() done (sqlalchemy)\n",
      "to_sql_insert_copy() done \n",
      "Nrows = 100000\n",
      "single_inserts() done\n",
      "execute_many() done\n",
      "execute_batch() done\n",
      "execute_values() done\n",
      "execute_mogrify() done\n",
      "copy_from_file() done\n",
      "copy_from_stringio() done\n",
      "to_sql() done (sqlalchemy)\n",
      "to_sql_insert_copy() done \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nrows</th>\n",
       "      <th>strategy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>single_inserts</td>\n",
       "      <td>0.622065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>execute_many</td>\n",
       "      <td>0.537997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>execute_batch</td>\n",
       "      <td>0.0361081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index nrows        strategy       time\n",
       "0      0  1000  single_inserts   0.622065\n",
       "1      1  1000    execute_many   0.537997\n",
       "2      2  1000   execute_batch  0.0361081"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lst = []\n",
    "\n",
    "for nrows in [1000,10000,50000,100000]:\n",
    "    print(\"Nrows = %s\" % nrows)\n",
    "    test_df = big_df[0:nrows]\n",
    "    perf_df = benchmark_bulk_inserts(test_df)\n",
    "    df_lst.append(perf_df)\n",
    "    \n",
    "\n",
    "performances = pd.concat(df_lst, axis=0).reset_index()\n",
    "performances.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "for strategy in performances['strategy'].unique():\n",
    "    subset = performances[performances['strategy'] == strategy]\n",
    "    ax.plot(subset['nrows'], subset['time'], 'o--', label=strategy)\n",
    "\n",
    "plt.xlabel('Number of rows in dataframe')\n",
    "plt.ylabel('Execution time (sec)')\n",
    "plt.title(\"COMPARING THE DIFFERENT INSERT STRATEGIES\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.savefig(\"./all_insert_strategies.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION 1\n",
    "If you care about speed, avoid doing single inserts at all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "for strategy in performances['strategy'].unique():\n",
    "    if (strategy != 'single_inserts'):\n",
    "        subset = performances[performances['strategy'] == strategy]\n",
    "        ax.plot(subset['nrows'], subset['time'], 'o--', label=strategy)\n",
    "\n",
    "plt.xlabel('Number of rows in dataframe')\n",
    "plt.ylabel('Execution time (sec)')\n",
    "plt.title(\"COMPARING THE BULK INSERT STRATEGIES\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.savefig(\"./benchmark.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I've been tasked with curating raw data from several large(in size: order of Gigs) CSV source files. \n",
    "I often struggle from managing the large dataframes while loading into the database as it took me time to process the entire workflows.  \n",
    "The below graph shows a performance benchmark of different PostgreSQL bulk insert methods of a relatively large Pandas dataframe that largely improved my work process. \n",
    "It was inspired by the approach described by Dat Tran in his Tips and I took on the work done by Naysan Saran to identify the most efficient approach. \n",
    "It clearly shows that the pandas to_sql() function definitely outperforms some common approaches by only supplying one additional parameter which is a callable method with yet an well pre-defined signature. \n",
    "Refer to this notebook to reproduce this experiment: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION 2\n",
    "\n",
    "\n",
    "So **execute_values()** and **execute_mogrify()** are doing fine...but the fastest way is to use **copy_from**. You can either  \n",
    "  * save your dataframe to a stringio object and load it directly to SQL, or\n",
    "  * save your dataframe to disk and load it to SQL\n",
    "  \n",
    "I don't know about you, but it is kind of sad to see that a good old copy is doing a better job than execute_values() and execute_mogrify()... But sometimes low tech is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd5b42e14f2b3fd946fcd1e6de145a7c016727ea3c92ad19cf395e8ad474535f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('ds37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
